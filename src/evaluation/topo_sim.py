#!/usr/bin/env python
"""
Measuring the topographical similarity

Referred the implementation at
https://github.com/facebookresearch/EGG/blob/main/egg/zoo/compo_vs_generalization/intervention.py"""

import editdistance
import torch
from scipy.stats import spearmanr
from scipy import spatial
from copy import deepcopy

class TopoSimEval:
    def __init__(self, model, datamodule, n_sample=10000):
        super(TopoSimEval, self).__init__()
        self.model = model
        datamodule.prepare_data()
        datamodule.setup()
        self.datamodule = datamodule
        self.n_sample = n_sample

    def eval(self):
        train_messages, train_attributes, train_msg_len = infer_message(self.model, self.datamodule.train_dataloader(), self.n_sample)
        test_messages, test_attributes, test_msg_len = infer_message(self.model, self.datamodule.test_dataloader(), self.n_sample)

        res_train = topographic_similarity(train_messages, train_attributes, train_msg_len)
        res_test = topographic_similarity(test_messages, test_attributes, test_msg_len)
        return {
            f'topsim_train_{self.n_sample}': res_train,
            f'topsim_test_{self.n_sample}': res_test,
                }


def infer_message(model, dataloader, sampling=False, n_sample=1000):
    with torch.no_grad():
        model.eval()
        device = next(model.parameters()).device

        latents, targets, eos_ids = [], [], []
        n = 0
        for x, t in dataloader:
            x = x.to(device=device)
            res = model.encode(x, sampling=sampling)
            z = res['z']
            eos_id = res['eos_id']
            latents.append(z.cpu())
            targets.append(deepcopy(t))
            eos_ids.append(eos_id.cpu())
            n += x.shape[0]
            if n >= n_sample:
                break

    latents = torch.cat(latents)[:n_sample]
    targets = torch.cat(targets)[:n_sample]
    eos_ids = torch.cat(eos_ids)[:n_sample]
    return latents.argmax(-1).numpy(), targets.numpy(), eos_ids.numpy()


def topographic_similarity(messages, attributes, msg_len=None):
    """

    :param messages: discrete messages generated by models. numpy arrays of shape N_samples X max_len
    :param attributes: ground truth attributes. numpy arrays of shape N_samples X N_attributes
    :param msg_len: arrays of length for each message in messages
    :return:
    """
    if msg_len is not None:
        messages_string = []
        for i, s in enumerate(messages):
            messages_string.append([x.item() for x in s[:msg_len[i]]])
    else:
        messages_string = messages
    distance_messages = edit_dist(messages_string)
    distance_inputs = cosine_dist(attributes.astype(float))

    corr = spearmanr(distance_messages, distance_inputs).correlation
    return corr

def edit_dist(_list):
    distances = []
    count = 0
    for i, el1 in enumerate(_list[:-1]):
        for j, el2 in enumerate(_list[i + 1 :]):
            count += 1
            # Normalized edit distance (same in our case as length is fixed)
            distances.append(editdistance.eval(el1, el2) / max(len(el1), len(el2)))
    return distances

def cosine_dist(_list):
    """

    :param _list:
    :return:
    """
    distances = []
    for i, el1 in enumerate(_list[:-1]):
        for j, el2 in enumerate(_list[i + 1 :]):
            distances.append(spatial.distance.cosine(el1, el2))
    return distances


